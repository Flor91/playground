0
00:00:00,000 --> 00:00:01,210


1
00:00:01,210 --> 00:00:03,450
Data cleaning helps to deal with missing data.

2
00:00:03,450 --> 00:00:09,130
For example, one censor data set might have humidity

3
00:00:09,130 --> 00:00:10,575
while the other does not.

4
00:00:10,575 --> 00:00:14,000
Data cleaning also helps to deal with entity resolution,

5
00:00:14,000 --> 00:00:16,276
so for example, the difference between IBM

6
00:00:16,276 --> 00:00:19,100
versus International Business Machines.

7
00:00:19,100 --> 00:00:21,300
It also helps to deal with unit mismatch.

8
00:00:21,300 --> 00:00:24,010
For example, in one data set, you might have dollars.

9
00:00:24,010 --> 00:00:28,000
In another, you might have pounds, and so on.

10
00:00:28,000 --> 00:00:31,490
Now, the statistics view of how you deal with data that's dirty

11
00:00:31,490 --> 00:00:34,260
is that there's a process that produces data,

12
00:00:34,260 --> 00:00:37,740
and we want to model ideal samples from that process.

13
00:00:37,740 --> 00:00:40,690
But in practice, we have non-ideal samples.

14
00:00:40,690 --> 00:00:42,910
That's because of distortion-- some samples

15
00:00:42,910 --> 00:00:44,690
are corrupted by a process.

16
00:00:44,690 --> 00:00:47,600
Selection bias-- the likelihood of a sample

17
00:00:47,600 --> 00:00:49,360
depends on its value.

18
00:00:49,360 --> 00:00:51,530
And left and right censorship, where

19
00:00:51,530 --> 00:00:54,350
we have users that come and go from our scrutiny.

20
00:00:54,350 --> 00:00:56,470
So censors, for example, that enter

21
00:00:56,470 --> 00:01:00,240
our data set at some point and then leave our data set.

22
00:01:00,240 --> 00:01:03,510
And dependence-- samples that are supposed to be independent

23
00:01:03,510 --> 00:01:04,239
but are not.

24
00:01:04,239 --> 00:01:05,970
So for example, in social networks,

25
00:01:05,970 --> 00:01:08,370
individuals within a social network

26
00:01:08,370 --> 00:01:10,810
are not necessarily independent.

27
00:01:10,810 --> 00:01:14,050
So we can add models for each type of imperfection,

28
00:01:14,050 --> 00:01:16,652
but the challenge is we can't model everything.

29
00:01:16,652 --> 00:01:18,360
So we have to think about what's the best

30
00:01:18,360 --> 00:01:22,300
trade-off between accuracy and simplicity.

31
00:01:22,300 --> 00:01:26,930
From the database point of view with dirty data is as follows.

32
00:01:26,930 --> 00:01:29,690
So I've got my hands on this data set.

33
00:01:29,690 --> 00:01:32,640
Some of the values are missing, or corrupted, or wrong,

34
00:01:32,640 --> 00:01:33,870
or duplicated.

35
00:01:33,870 --> 00:01:36,850
But results are absolute because we have this relational model.

36
00:01:36,850 --> 00:01:40,180
And so we get a better answer by improving the quality

37
00:01:40,180 --> 00:01:43,040
of values in the data set.

38
00:01:43,040 --> 00:01:45,200
The domain expert's view of dirty data

39
00:01:45,200 --> 00:01:46,880
is that this data doesn't look right,

40
00:01:46,880 --> 00:01:48,680
or this answer doesn't look right.

41
00:01:48,680 --> 00:01:50,690
So they want to understand what happened.

42
00:01:50,690 --> 00:01:52,955
And domain experts have an inclusive model of the data

43
00:01:52,955 --> 00:01:56,300
that they can test against.

44
00:01:56,300 --> 00:02:01,080
A data scientist's view is some combination of all of the above

45
00:02:01,080 --> 00:02:04,070
when they're looking at dirty data.

