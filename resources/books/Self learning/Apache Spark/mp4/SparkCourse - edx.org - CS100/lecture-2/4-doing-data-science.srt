0
00:00:00,000 --> 00:00:00,980


1
00:00:00,980 --> 00:00:04,010
so now let's look at how we perform data science.

2
00:00:04,010 --> 00:00:06,900
We'll do this by first looking at the view of three data

3
00:00:06,900 --> 00:00:10,580
science experts-- Jim Gray who was a Turing Award-winning

4
00:00:10,580 --> 00:00:15,260
database researcher, Ben Fry who is a data visualization expert,

5
00:00:15,260 --> 00:00:17,780
and Jeff Hammerbacher, who's a former Facebook chief

6
00:00:17,780 --> 00:00:20,060
scientists and Cloudera co-founder.

7
00:00:20,060 --> 00:00:22,280
Then we'll look at cloud computing, which has

8
00:00:22,280 --> 00:00:25,940
become a data science enabler.

9
00:00:25,940 --> 00:00:28,580
So recall that we had this definition of data science.

10
00:00:28,580 --> 00:00:32,409
It combines hacking skills along with math and statistics

11
00:00:32,409 --> 00:00:36,880
knowledge along with domain expertise.

12
00:00:36,880 --> 00:00:39,340
So let's start with Jim Gray's model.

13
00:00:39,340 --> 00:00:43,960
His model is that you capture data, then curate that data,

14
00:00:43,960 --> 00:00:48,010
and then you communicate the results.

15
00:00:48,010 --> 00:00:53,310
So Ben Fry's model takes this down a level of granularity.

16
00:00:53,310 --> 00:00:56,770
Ben Fry starts by first acquiring data, then parsing

17
00:00:56,770 --> 00:00:59,970
that data, then filtering the data,

18
00:00:59,970 --> 00:01:04,239
mining the data for information, representing the results,

19
00:01:04,239 --> 00:01:10,790
refining the model, and then interacting with the results.

20
00:01:10,790 --> 00:01:14,560
Jeff Hammerbacher takes this even a level further.

21
00:01:14,560 --> 00:01:18,200
He starts first by identifying a problem,

22
00:01:18,200 --> 00:01:22,850
instrumenting the data sources, then collecting the data

23
00:01:22,850 --> 00:01:24,250
and then preparing that data.

24
00:01:24,250 --> 00:01:26,080
And that involves integrating the data,

25
00:01:26,080 --> 00:01:28,960
transforming it, cleaning it, filtering it,

26
00:01:28,960 --> 00:01:30,610
and aggregating it.

27
00:01:30,610 --> 00:01:32,590
And then he builds a model.

28
00:01:32,590 --> 00:01:36,730
He then evaluates that model and then communicates the results.

29
00:01:36,730 --> 00:01:38,250
So in each of these cases, you can

30
00:01:38,250 --> 00:01:44,450
see how we start with a problem, we collect data,

31
00:01:44,450 --> 00:01:46,920
we clean that data, build a model,

32
00:01:46,920 --> 00:01:49,760
and then we communicate the results.

